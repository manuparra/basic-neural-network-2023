{"cells":[{"cell_type":"markdown","metadata":{"id":"ZDitZsQALa1H"},"source":["# HANDS-ON PRACTICE SESSION 3: PRACTICAL CONSIDERATIONS"]},{"cell_type":"markdown","metadata":{"id":"Wi84rOu4si0V"},"source":["SO Basics of Neural Networks 2023 school at the IAA-CSIC. Nov 2023.  \n","Eduardo Sánchez Karhunen  (fesanchez@us.es)  \n","University of Seville. Spain.  Dept. of CS and AI"]},{"cell_type":"markdown","metadata":{"id":"pi-LyvK2V070"},"source":["### Introduction"]},{"cell_type":"markdown","metadata":{"id":"1EQPOjdLUGZC"},"source":["In the last session, a CNN was designed to tackle the Galaxy10 classification problem. The obtained accuracy was approx. 71%.\n","\n","In this third practice we are going to apply some improvements to our CNNs. Basically:\n","* Early Stopping\n","* Drop-out\n","* Data-Augmentation\n","\n","The final goal of these techniques is to obtain an improvement in the network classification results, fighting against the overfitting."]},{"cell_type":"markdown","metadata":{"id":"tLgenWShFb0N"},"source":["### 1. Loading libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x3FXwlSEgKYa"},"outputs":[],"source":["import numpy as np\n","import h5py\n","import tensorflow as tf\n","import pandas as pd\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6-Bbu7KcLUPe"},"outputs":[],"source":["# only execute this lines if the following error appears\n","# OMP: Error #15: Initializing libiomp5md.dll, but found libiomp5md.dll already initialized.\n","\n","# import os\n","# os.environ['KMP_DUPLICATE_LIB_OK']='True'"]},{"cell_type":"markdown","metadata":{"id":"kVhPclDLgYUu"},"source":["### Exercise 0: Dataset preparation"]},{"cell_type":"markdown","metadata":{"id":"iCjX9i4egb-q"},"source":["As in the previous session, download the dataset to your local disk."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A6x2TeCbjZ95","outputId":"8f56dca8-a9cd-4eba-c25c-e1312f99f71a","executionInfo":{"status":"ok","timestamp":1699829293176,"user_tz":-60,"elapsed":17172,"user":{"displayName":"Eduardo Sanchez Karhunen","userId":"07705693878574082533"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-11-12 22:47:55--  http://www.astro.utoronto.ca/~bovy/Galaxy10/Galaxy10.h5\n","Resolving www.astro.utoronto.ca (www.astro.utoronto.ca)... 128.100.89.92\n","Connecting to www.astro.utoronto.ca (www.astro.utoronto.ca)|128.100.89.92|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 210234548 (200M)\n","Saving to: ‘Galaxy10.h5.1’\n","\n","Galaxy10.h5.1       100%[===================>] 200.50M  13.6MB/s    in 17s     \n","\n","2023-11-12 22:48:12 (12.1 MB/s) - ‘Galaxy10.h5.1’ saved [210234548/210234548]\n","\n"]}],"source":["# LINUX\n","!wget http://www.astro.utoronto.ca/~bovy/Galaxy10/Galaxy10.h5\n","\n","# WINDOWS\n","# !curl \"http://www.astro.utoronto.ca/~bovy/Galaxy10/Galaxy10.h5\" --output Galaxy10.h5"]},{"cell_type":"markdown","metadata":{"id":"r9HHkcMxjfAN"},"source":["Convert the downloaded h5 files into two numpy arrays containing images and labels."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NjrXTGkNgWCt"},"outputs":[],"source":["hf = h5py.File('Galaxy10.h5', 'r')\n","labels, images = hf.get('ans')[()], hf.get('images')[()]"]},{"cell_type":"markdown","metadata":{"id":"P8fXWNW0m09i"},"source":["Check the shape of the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WDKwAL3KmboB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699829297711,"user_tz":-60,"elapsed":32,"user":{"displayName":"Eduardo Sanchez Karhunen","userId":"07705693878574082533"}},"outputId":"921ecb9b-6d91-479e-8dd9-ac93bb7a83e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["number of images: 21785\n","shape of each image: [69, 69]\n","number of channels: 3\n"]}],"source":["n_images, *shape, n_channels = images.shape\n","print(f\"number of images: {n_images}\")\n","print(f\"shape of each image: {shape}\")\n","print(f\"number of channels: {n_channels}\")"]},{"cell_type":"markdown","metadata":{"id":"pXIX7lGyu2Nc"},"source":["### Exercise 1. Create train and test datasets"]},{"cell_type":"markdown","metadata":{"id":"97_KZhmhvaiU"},"source":["Divide the dataset into two new datasets for:\n","* training: 90%\n","* test: 10%  \n","\n","Use the `train_test_split` command from scikit_learn. Do not worry for the validation dataset. We will create it in a posterior step.\n","\n","More info in: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n","\n","**Task:** Create the following arrays: `train_images`, `train_labels`, `test_images` and `test_labels`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SqRFDFSjsG78"},"outputs":[],"source":["# your code here\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6o-TvQe6B8kr"},"source":["### Exercise 2. Initialize ImageGenerators"]},{"cell_type":"markdown","metadata":{"id":"r1AyMaUOCEQX"},"source":["ImageGenerators are needed to apply data-augmentation. It can be taken advantage of them to rescale and split data into train and validation in the same step.\n","\n","Remember:\n","* Scaling the pixel values is always needed. Use the param `rescale` to indicate de scaling value.\n","* As a network designer you must decide which augmentation techniques fit better to your concrete problem. Probably some of them are not useful and can produce confusion between classes. In this case you can safely use horizontal flip.\n","\n","* We can also split validation data at this moment. Using `validation_split` argument to indicate the size. A typical split value is 0.2.\n","\n","More info in: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n","\n","**Task:** Create an ImageDataGenerator to rescale, split validation data and apply horizontal flip aaugmentations."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pQx8CPhg_n_H"},"outputs":[],"source":["# your code here\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"QwTDLT6rDwmc"},"source":["### Exercise 3. Connect ImageGenerators with data arrays"]},{"cell_type":"markdown","metadata":{"id":"Ywk_PL5XFn21"},"source":["Once created the generator, it must be applied to our data arrays. Depending of the data location, different methods can be applied:\n","\n","* **flow_from_directory**: if data is stored in the typical folder structure (one folder for each class).\n","* **flow**: when data in stored in numpy arrays in memory. Our Galaxy10 dataset is enough small to load it into a numpy array in memory.\n","\n","More info in: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow and https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory\n","\n","**Task:** Create two generators `train_generator`and `validation_generator` connected with arrays `train_images` and `train_labels`.\n","\n","Hint: in both cases, the input arguments are the same: train_images and train_labels. The third argument indicates if the desired gen is for training or for validation.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RmBl0ggT_-_2"},"outputs":[],"source":["# your code here\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GpvRWsl7_BTX"},"source":["### Exercise 4. Building the CNN model"]},{"cell_type":"markdown","metadata":{"id":"mSsim3bj_QLA"},"source":["Remember to follow this same schema:\n","\n","<br>\n","\n","![picture](https://drive.google.com/uc?id=1k8aHjwHlRP3wgU-IAtpKbcvwqyvvyUwY)\n"]},{"cell_type":"markdown","metadata":{"id":"x3xbAOQlDgQn"},"source":["The parameters of the different layers are:\n","\n","A) Convolutional layer\n","* 12 kernels (3x3)\n","* Stride = 1. The kernel will be shifted pixel by pixel along the image.\n","* No-padding. In Tensorflow, this is indicated as padding = `valid`.\n","\n","B) Pooling layer\n","* pool_size = 2x2\n","* stride = 2\n","\n","C) Flatten layer  \n","D) Two dense layers with 500 and 100 neurons, respectively.\n","\n","**Task:** create a `conv_1`, `pool_1`, `flatten_layer`, `dense_1`, `dense_2` and `output_layer` with the previous parameters."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jr1NCfO_vZ3A"},"outputs":[],"source":["# your code here\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GgebuHElPud0"},"source":["### Exercise 5. Dropout layer"]},{"cell_type":"markdown","metadata":{"id":"hLuTaX52P_Oa"},"source":["Dropout layers can be inserted almost in any position in the network. We will add three of them after the flatten and both dense layers.\n","\n","More info: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout\n","\n","**Task:** Create three dropout layers `do_1`, `do_2` and `do_3` with drop_rate 0.35."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BfRZOK0MPuur"},"outputs":[],"source":["# your code here\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"4nNvqt3JJDrM"},"source":["### Exercise 6. Join all layers in a CNN"]},{"cell_type":"markdown","metadata":{"id":"o0Ckn1JFJDzi"},"source":["The first step is to create a `sequential` structure to be filled with the previously created layers.\n","\n","More info in: https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n","\n","**Task:** Collect all the previous layers in a `model`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rOi42HQEJ2Yt"},"outputs":[],"source":["# your code here\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"pU4zT3O0sfGu"},"source":["### Exercise 7. Model inspection"]},{"cell_type":"markdown","metadata":{"id":"pHRg_0oiv5Jv"},"source":["In the model summary we can check the three new dropout layers have been added. Of course, these layers have no parameters.\n","\n","**Task:** show a summary of the network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dt_lQeyssnFo"},"outputs":[],"source":["# your code here\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"4ob6iG2AKnAg"},"source":["### Exercise 8. Assign loss function and optimizer"]},{"cell_type":"markdown","metadata":{"id":"rcO61kgUKnMw"},"source":["**Task:** assign the classical parameters to the network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"foO3WkdvLBpP"},"outputs":[],"source":["# your code here\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"86qmNpmIRaM8"},"source":["### Exercise 9. Create an early stopping callback"]},{"cell_type":"markdown","metadata":{"id":"hksGz0yURiBr"},"source":["Remeber EarlyStopping has two parameters:\n","* patience\n","* restore_best_weights\n","\n","**Task:** Create an early stopping callback `es_callback` with patience = 4. Restore best weights when training finishes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w6NW6_UYRaa1"},"outputs":[],"source":["# your code here\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GZ-rDDyxN3q6"},"source":["### Exercise 10. Network training"]},{"cell_type":"markdown","metadata":{"id":"-mPWZtqjN33d"},"source":["Remember:\n","* Use early stopping in training via the `callbacks` parameter. It expects a list, even if there is only one callback\n","* Validation_split is no more needed because this task has been performed by our generators.\n","* Use as training and validation data the two previously created generators\n","* Increase the number of epochs e.g. 30 epochs.\n","\n","More info: https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\n","\n","**Task:** Train the model with the selected number of epochs, callback and using the generators (save the training history)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DKsg-lj4OESP"},"outputs":[],"source":["# your code here\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"XJdEtcPHtQOM"},"source":["### Exercise 11: Plot training history"]},{"cell_type":"markdown","metadata":{"id":"fQwgqfERxPUW"},"source":["It is a good practice to plot our training curves. Typically we compare the evolution of loss function (accuracy) vs epochs.\n","\n","**Task:** Plot train and valid loss (and accuracy) evolution during training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SUkk-7iPvvVh"},"outputs":[],"source":["# your code here\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hu8QYYqrtzum"},"source":["### Exercise 12. Evaluate model accuracy"]},{"cell_type":"markdown","source":["To evaluate the model accuracy in the test dataset, first you must rescale `test_images`. You can do it in the traditional way, as in the previous practices or creating a generator simply for scaling.\n","\n","**Task:** Once trained the model, obtain the accuracy of the model on the test dataset."],"metadata":{"id":"46b1IXNhgOUp"}},{"cell_type":"code","source":["# your code here\n","\n","\n"],"metadata":{"id":"pn1k_dqMBLkV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WBZVdHVBvTdJ"},"source":["### Exercise 13: Making predictions with the model"]},{"cell_type":"markdown","metadata":{"id":"jdpuyqs0wLG6"},"source":["Given an input image, the `predict` method returns the output of the last layer. This output is interpreted as the probability of the image to correspond to each of the classes.\n","\n","**Task:** Inject to the model 3 images from the test dataset to obtain their probabilities."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MSP-v89qxLge"},"outputs":[],"source":["# your code here\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"WYcLKXWdjjK0"},"source":["**Task:** Using `np.argmax` and the probabilities, decide which is the class of each image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EDMjBie4x1jr"},"outputs":[],"source":["# your code here\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"MwYtZX7WlRJr"},"source":["**Task:** Finally, compare the predicted classes with the real ones. There should be approx. 75% of correct predictions."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0UvldzKRyp2f"},"outputs":[],"source":["# your code here\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KkDq62QLysp1"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}